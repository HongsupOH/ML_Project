{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import sys\n",
    "from bingo.evolutionary_optimizers.parallel_archipelago \\\n",
    "    import load_parallel_archipelago_from_file\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from ipywidgets import interact\n",
    "import os\n",
    "import gc\n",
    "import h5py\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\"fs1d29e10_even/pkl_files/\"]\n",
    "\n",
    "def get_labels(filename):\n",
    "    label_map = {\"pql\": [\"Sig_h\", \"Sig_vm\", \"Lode\", \"vvf\"],\n",
    "                 \"haigh_westergaard\": [\"z\", \"r\", \"theta\", \"eps\", \"vvf\"],\n",
    "                 \"invariants\": [\"I1\", \"J2\", \"J3\", \"eps\", \"vvf\"],\n",
    "                 \"principle_stresses\": [\"Sig_1\", \"Sig_2\", \"Sig_3\", \"eps\", \"vvf\"],\n",
    "                 \"custom\": [\"Sig_h\", \"Sig_vm\", \"vvf\"], # use for runs before July\n",
    "                 \"lode\": [\"Sig_h\",\"Sig_vm\",\"Lode\",\"vvf\"],\n",
    "                 \"no_lode\": [\"Sig_h\", \"Sig_vm\", \"vvf\"],\n",
    "                  \"porosity\": [\"vvf\", \"del_vvf\", \"del_PE11\", \"del_PE22\"]}\n",
    "    for key, label in label_map.items():\n",
    "        if key in filename:\n",
    "            return label\n",
    "    return None\n",
    "        \n",
    "data_label_map = {}\n",
    "for d in directories:\n",
    "    for f in os.listdir(d):\n",
    "        if f.endswith(\".pkl\"):\n",
    "            labels = get_labels(f)\n",
    "            data_label_map[os.path.join(d, f)] = labels\n",
    "\n",
    "hof_index_list = [i for i in range(-10, 10)]\n",
    "filename_list = list(data_label_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(hof_index_list)\n",
    "print(filename_list)\n",
    "# print(data_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_eq_and_fitness(filename, hof_index=0):\n",
    "    archipelago = load_parallel_archipelago_from_file(filename)\n",
    "    hof = archipelago.hall_of_fame\n",
    "    equation = hof[hof_index]\n",
    "#     equation2 = equation.copy()\n",
    "#     equation2._use_simplification = True\n",
    "#     equation2._update()\n",
    "\n",
    "    print('Equation:', equation)\n",
    "#     print('Simplified Equation:', equation2)\n",
    "    print('Fitness:', hof[hof_index].fitness)\n",
    "    print('Complexity:', hof[hof_index].get_complexity())\n",
    "    allhofs = np.arange(-10,10,1)\n",
    "    allfitness = []\n",
    "    for i in allhofs:\n",
    "        allfitness.append(hof[i].fitness)\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     ax.plot(allhofs,allfitness)\n",
    "#     ax.set_ylabel('Fitness')\n",
    "#     ax.set_xlabel('Hof Index')\n",
    "#     fig.show()\n",
    "    \n",
    "interact(print_eq_and_fitness, filename=filename_list, hof_index=hof_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pareto(filename, hof_index=0):\n",
    "    archipelago = load_parallel_archipelago_from_file(filename)\n",
    "    hof = archipelago.hall_of_fame\n",
    "    equation = hof[hof_index]\n",
    "    \n",
    "    print('Equation:', equation)\n",
    "    print('Fitness:', hof[hof_index].fitness)\n",
    "    print('Complexity:', hof[hof_index].get_complexity())\n",
    "    allhofs = np.arange(-10,10,1)\n",
    "    hofspos = np.arange(0,11)\n",
    "    hofsneg = np.arange(-10,0)\n",
    "    allhofs = np.concatenate((hofspos, hofsneg), axis=None)\n",
    "    allfitness = []\n",
    "    allcomplexity = []\n",
    "    for i in allhofs:\n",
    "        allfitness.append(hof[i].fitness)\n",
    "        allcomplexity.append(hof[i].get_complexity())\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.step(allcomplexity,allfitness,'k',where='post')\n",
    "    ax.plot(allcomplexity,allfitness,'ro')\n",
    "    ax.set_ylabel('Fitness')\n",
    "    ax.set_xlabel('Complexity')\n",
    "    fig.show()\n",
    "    \n",
    "interact(plot_pareto, filename=filename_list, hof_index=hof_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data_and_labels(filename, hof_index=None, fit_func=False):\n",
    "    archipelago = load_parallel_archipelago_from_file(filename)\n",
    "    data = archipelago.island._full_training_data\n",
    "#     data = archipelago._island._ea.evaluation.fitness_function.training_data \n",
    "    data_labels = data_label_map[filename]\n",
    "    output = (data, data_labels)\n",
    "    if hof_index is not None:\n",
    "        hof = archipelago.hall_of_fame\n",
    "        output += (hof[hof_index],)\n",
    "    \n",
    "    if fit_func:\n",
    "        ff = archipelago.island._fitness_function\n",
    "        output += (ff,)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will plot the mean of the function evaluated at the data\n",
    "def mean_data(filename, hof_index=0):\n",
    "    \n",
    "    data, data_labels, equation = _get_data_and_labels(filename, hof_index)\n",
    "    equation_2 = equation.copy()\n",
    "#     equation_2._use_simplification = False\n",
    "    print(equation_2)\n",
    "    data = data.x\n",
    "    print(data)\n",
    "    print(np.shape(data))\n",
    "    equ_eval = equation.evaluate_equation_at(data) # evaluate the equation at the data (if the equation was Gurson, this would give zero at all data points)\n",
    "    mean_const = np.mean(equ_eval) \n",
    "    print(mean_const)\n",
    " \n",
    "\n",
    "interact(mean_data, filename=filename_list, hof_index=hof_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_data(filename, x_ind=0, y_ind=1):\n",
    "    data, data_labels = _get_data_and_labels(filename)\n",
    "    print(data.x.shape)\n",
    "    data_labels = ['Sig_h', 'Sig_vm']\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(data.x[:, x_ind], data.x[:, y_ind])    \n",
    "    \n",
    "interact(plot_data, filename=filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(filename, x_ind=0, y_ind=1, z_ind=2, c_ind=3):\n",
    "    data, data_labels = _get_data_and_labels(filename)\n",
    "    print(data.x.shape)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    sc = ax.scatter(data.x[:, x_ind], data.x[:, y_ind], data.x[:, z_ind], c=data.x[:, c_ind])\n",
    "    ax.set_xlabel(data_labels[x_ind])\n",
    "    ax.set_ylabel(data_labels[y_ind])\n",
    "    ax.set_zlabel(data_labels[z_ind])\n",
    "    fig.colorbar(sc)\n",
    "    \n",
    "interact(plot_data, filename=filename_list, x_ind=range(5), y_ind=range(5), z_ind=range(5), c_ind=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_data_and_potential_field(filename, hof_index=0, x_ind=0, y_ind=1, z_ind=3):\n",
    "    \n",
    "    data, data_labels, equation = _get_data_and_labels(filename, hof_index)\n",
    "    equation_2 = equation.copy()\n",
    "    equation_2._use_simplification = False\n",
    "#     equation_2._update()\n",
    "    print(equation_2)\n",
    "    data = data.x\n",
    "    mean_data = np.mean(data, axis=0) # gets the mean hydrostatic, von Mises, Lode, vvf\n",
    "    syield = 1 # this assumes the yield stress is normalized! make sure I always normalize in run_bingo.py\n",
    "    equ_eval = equation.evaluate_equation_at(data) # evaluate the equation at the data (if the equation was Gurson, this would give zero at all data points)\n",
    "    mean_const = np.mean(equ_eval) \n",
    "    std_const = np.std(equ_eval)\n",
    "    gurson = (data[:,1]/syield)**2+2*data[:,3]*np.cosh(1.5*(data[:,0]/syield))-(1+data[:,3]**2)\n",
    "    mean_gurson = np.mean(gurson)\n",
    "#     rel_per_diff = np.mean(np.absolute((gurson-equ_eval))) # THIS CAUSES THE KERNEL TO CRASH\n",
    "#     print(rel_per_diff)\n",
    "    npts = 50\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x_vec = np.linspace(np.min(data[:,x_ind]), np.max(data[:,x_ind]), npts)\n",
    "    y_vec = np.linspace(np.min(data[:,y_ind]), np.max(data[:,y_ind]), npts)\n",
    "    z_vec = np.linspace(np.min(data[:,z_ind]), np.max(data[:,z_ind]), npts)\n",
    "    x, y = np.meshgrid(x_vec, y_vec) # so here he's just got a meshgrid of all the von Mises and hydrostatic stresses from his data\n",
    "\n",
    "#     #levels = np.linspace(mean_const -2*std_const, mean_const + 2*std_const, 7)\n",
    "    levels = [mean_const]             # these levels define what part of the contours he wants to show up, i.e. just pretty much 0\n",
    "    levels_gurson = [mean_gurson]\n",
    "#     levels = [0]\n",
    "#     levels_gurson = [0]\n",
    "    print(levels)\n",
    "    print(levels_gurson)\n",
    "    \n",
    "    for z in z_vec: # for each porosity he's doing this \n",
    "        flat_data = np.vstack([np.full_like(x.flatten(), m) for m in mean_data]).T\n",
    "        flat_data[:, x_ind] = x.flatten()\n",
    "        flat_data[:, y_ind] = y.flatten()\n",
    "        flat_data[:, z_ind] = z \n",
    "        F = equation.evaluate_equation_at(flat_data).reshape(x.shape)\n",
    "        F_gurson = (flat_data[:,1]/syield)**2+2*flat_data[:,3]*np.cosh(1.5*(flat_data[:,0]/syield))-(1+flat_data[:,3]**2)\n",
    "        F_gurson = F_gurson.reshape(x.shape)\n",
    "        # so here's what's happening: the \"F\" from the Gurson evaluation is what the z part of his contour is. \n",
    "        # then, with levels, he only includes the contours at THAT level, i.e. at 0 where those points satisfy\n",
    "        # being on the Gurson yield surface. Now, he has the curves at 0, and simply just moves them up to where \n",
    "        # they should be. I think this looks pretty legit, can't really see anything wrong with it. \n",
    "        # PUT SHORTLY: he loops through different vvf's present in the data; using those vvfs, gets the curve \n",
    "        # through all the stresses that satisfy Gurson. \n",
    "        # ONE question I guess: Why is he defining the levels based off of the mean value of the Gurson yield function\n",
    "        # on his data? Why not just at 0 where the surface would be? \n",
    "        cset = ax.contour(x, y, F, levels, offset=z,colors='red')\n",
    "        cset_gurson = ax.contour(x, y, F_gurson, levels_gurson, offset=z,colors='blue')\n",
    "            \n",
    "#     sc = ax.scatter(data[::50, x_ind], data[::50, y_ind], data[::50, z_ind], c=\"k\")\n",
    "    sc = ax.scatter(data[:, x_ind], data[:, y_ind], data[:, z_ind], c=\"k\")\n",
    "    ax.set_xlabel(data_labels[x_ind])\n",
    "    ax.set_ylabel(data_labels[y_ind])\n",
    "    ax.set_zlabel(data_labels[z_ind])\n",
    "    ax.set_xlim(x_vec[0], x_vec[-1])\n",
    "    ax.set_ylim(y_vec[0], y_vec[-1])\n",
    "    ax.set_zlim(z_vec[0], z_vec[-1])\n",
    "#     fig.colorbar(cset)\n",
    "    plt.show()\n",
    "    \n",
    "#     threshold = 0.25\n",
    "#     F_gurson = F_gurson.flatten()\n",
    "#     F = F.flatten()\n",
    "#     rel_perc_diff = np.zeros(len(F_gurson))\n",
    "#     for i in range(0,len(F_gurson)):\n",
    "#         if F_gurson[i] <= threshold:\n",
    "#             rel_perc_diff[i] = rel_perc_diff[i-1]\n",
    "#         else:\n",
    "#             rel_perc_diff[i] = np.absolute((F_gurson[i]-F[i])/F_gurson[i]*100)\n",
    "#     print(np.mean(rel_perc_diff))\n",
    "\n",
    "interact(plot_data_and_potential_field, filename=filename_list, hof_index=hof_index_list,\n",
    "         x_ind=range(5), y_ind=range(5), z_ind=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_and_potential_field_noLode(filename, hof_index=0, x_ind=0, y_ind=1, z_ind=2):\n",
    "    \n",
    "    data, data_labels, equation = _get_data_and_labels(filename, hof_index)\n",
    "    equation_2 = equation.copy()\n",
    "    equation_2._use_simplification = False\n",
    "#     equation_2._update()\n",
    "    print(equation_2)\n",
    "    data = data.x\n",
    "    mean_data = np.mean(data, axis=0) # gets the mean hydrostatic, von Mises, vvf\n",
    "    syield = 1 # this assumes the yield stress is normalized! make sure I always normalize in run_bingo.py\n",
    "    equ_eval = equation.evaluate_equation_at(data) # evaluate the equation at the data (if the equation was Gurson, this would give zero at all data points)\n",
    "    mean_const = np.mean(equ_eval) \n",
    "    std_const = np.std(equ_eval)\n",
    "    gurson = (data[:,1]/syield)**2+2*data[:,2]*np.cosh(1.5*(data[:,0]/syield))-(1+data[:,2]**2)\n",
    "    mean_gurson = np.mean(gurson)\n",
    "#     rel_per_diff = np.mean(np.absolute((gurson-equ_eval))) # THIS CAUSES THE KERNEL TO CRASH\n",
    "#     print(rel_per_diff)\n",
    "    npts = 50\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x_vec = np.linspace(np.min(data[:,x_ind]), np.max(data[:,x_ind]), npts)\n",
    "    y_vec = np.linspace(np.min(data[:,y_ind]), np.max(data[:,y_ind]), npts)\n",
    "    z_vec = np.linspace(np.min(data[:,z_ind]), np.max(data[:,z_ind]), npts)\n",
    "    x, y = np.meshgrid(x_vec, y_vec) # so here he's just got a meshgrid of all the von Mises and hydrostatic stresses from his data\n",
    "\n",
    "#     #levels = np.linspace(mean_const -2*std_const, mean_const + 2*std_const, 7)\n",
    "    levels = [mean_const]             # these levels define what part of the contours he wants to show up, i.e. just pretty much 0\n",
    "    levels_gurson = [mean_gurson]\n",
    "#     levels = [0]\n",
    "#     levels_gurson = [0]\n",
    "    print(levels)\n",
    "    print(levels_gurson)\n",
    "    \n",
    "    for z in z_vec: # for each porosity he's doing this \n",
    "        flat_data = np.vstack([np.full_like(x.flatten(), m) for m in mean_data]).T\n",
    "        flat_data[:, x_ind] = x.flatten()\n",
    "        flat_data[:, y_ind] = y.flatten()\n",
    "        flat_data[:, z_ind] = z \n",
    "        F = equation.evaluate_equation_at(flat_data).reshape(x.shape)\n",
    "        F_gurson = (flat_data[:,1]/syield)**2+2*flat_data[:,2]*np.cosh(1.5*(flat_data[:,0]/syield))-(1+flat_data[:,2]**2)\n",
    "        F_gurson = F_gurson.reshape(x.shape)\n",
    "        # so here's what's happening: the \"F\" from the Gurson evaluation is what the z part of his contour is. \n",
    "        # then, with levels, he only includes the contours at THAT level, i.e. at 0 where those points satisfy\n",
    "        # being on the Gurson yield surface. Now, he has the curves at 0, and simply just moves them up to where \n",
    "        # they should be. I think this looks pretty legit, can't really see anything wrong with it. \n",
    "        # PUT SHORTLY: he loops through different vvf's present in the data; using those vvfs, gets the curve \n",
    "        # through all the stresses that satisfy Gurson. \n",
    "        # ONE question I guess: Why is he defining the levels based off of the mean value of the Gurson yield function\n",
    "        # on his data? Why not just at 0 where the surface would be? \n",
    "        cset = ax.contour(x, y, F, levels, offset=z,colors='red')\n",
    "        cset_gurson = ax.contour(x, y, F_gurson, levels_gurson, offset=z,colors='blue')\n",
    "            \n",
    "#     sc = ax.scatter(data[::50, x_ind], data[::50, y_ind], data[::50, z_ind], c=\"k\")\n",
    "    sc = ax.scatter(data[:, x_ind], data[:, y_ind], data[:, z_ind], c=\"k\")\n",
    "    ax.set_xlabel(data_labels[x_ind])\n",
    "    ax.set_ylabel(data_labels[y_ind])\n",
    "    ax.set_zlabel(data_labels[z_ind])\n",
    "    ax.set_xlim(x_vec[0], x_vec[-1])\n",
    "    ax.set_ylim(y_vec[0], y_vec[-1])\n",
    "    ax.set_zlim(z_vec[0], z_vec[-1])\n",
    "#     fig.colorbar(cset)\n",
    "    plt.show()\n",
    "    \n",
    "#     threshold = 0.25\n",
    "#     F_gurson = F_gurson.flatten()\n",
    "#     F = F.flatten()\n",
    "#     rel_perc_diff = np.zeros(len(F_gurson))\n",
    "#     for i in range(0,len(F_gurson)):\n",
    "#         if F_gurson[i] <= threshold:\n",
    "#             rel_perc_diff[i] = rel_perc_diff[i-1]\n",
    "#         else:\n",
    "#             rel_perc_diff[i] = np.absolute((F_gurson[i]-F[i])/F_gurson[i]*100)\n",
    "#     print(np.mean(rel_perc_diff))\n",
    "\n",
    "interact(plot_data_and_potential_field_noLode, filename=filename_list, hof_index=hof_index_list,\n",
    "         x_ind=range(5), y_ind=range(5), z_ind=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_and_potential_field_onlyyields(filename, hof_index=0, x_ind=0, y_ind=1, z_ind=2):\n",
    "    \n",
    "    data, data_labels, equation = _get_data_and_labels(filename, hof_index)\n",
    "    equation_2 = equation.copy()\n",
    "    equation_2._use_simplification = False\n",
    "#     equation_2._update()\n",
    "    print(equation_2)\n",
    "    data = data.x\n",
    "    mean_data = np.mean(data, axis=0)\n",
    "    syield = 1\n",
    "    \n",
    "    equ_eval = equation.evaluate_equation_at(data)\n",
    "    mean_const = np.mean(equ_eval)\n",
    "    std_const = np.std(equ_eval)\n",
    "    gurson = (data[:,1]/syield)**2+2*data[:,2]*np.cosh(1.5*(data[:,0]/syield))-(1+data[:,2]**2)\n",
    "    mean_gurson = np.mean(gurson) # gets the mean value of phi that Gurson evaluates to w/ the data? \n",
    "    rel_per_diff = np.mean(np.absolute((gurson-equ_eval)))\n",
    "#     print(rel_per_diff)\n",
    "    npts = 50\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x_vec = np.linspace(np.min(data[:,x_ind]), np.max(data[:,x_ind]), npts) \n",
    "    y_vec = np.linspace(np.min(data[:,y_ind]), np.max(data[:,y_ind]), npts)\n",
    "    z_vec = np.linspace(np.min(data[:,z_ind]), np.max(data[:,z_ind]), npts)\n",
    "    x, y = np.meshgrid(x_vec, y_vec) # gets a meshgrid of von Mises and hydrostatic stresses between mins and maxes in his data\n",
    "\n",
    "#     #levels = np.linspace(mean_const -2*std_const, mean_const + 2*std_const, 7)\n",
    "    levels = [mean_const]\n",
    "    levels_gurson = [mean_gurson]\n",
    "    \n",
    "    \n",
    "    for z in z_vec:\n",
    "        flat_data = np.vstack([np.full_like(x.flatten(), m) for m in mean_data]).T\n",
    "        flat_data[:, x_ind] = x.flatten()\n",
    "        flat_data[:, y_ind] = y.flatten()\n",
    "        flat_data[:, z_ind] = z\n",
    "        F = equation.evaluate_equation_at(flat_data).reshape(x.shape)\n",
    "        F_gurson = (flat_data[:,1]/syield)**2+2*flat_data[:,2]*np.cosh(1.5*(flat_data[:,0]/syield))-(1+flat_data[:,2]**2)\n",
    "        F_gurson = F_gurson.reshape(x.shape) \n",
    "        cset = ax.contour(x, y, F, levels, offset=z,colors='red')\n",
    "        cset_gurson = ax.contour(x, y, F_gurson, levels_gurson, offset=z,colors='blue')\n",
    "            \n",
    "    sc = ax.scatter(data[:, x_ind], data[:, y_ind], data[:, z_ind], c=\"k\")\n",
    "    ax.set_xlabel(data_labels[x_ind])\n",
    "    ax.set_ylabel(data_labels[y_ind])\n",
    "    ax.set_zlabel(data_labels[z_ind])\n",
    "    ax.set_xlim(x_vec[0], x_vec[-1])\n",
    "    ax.set_ylim(y_vec[0], y_vec[-1])\n",
    "    ax.set_zlim(z_vec[0], z_vec[-1])\n",
    "    #fig.colorbar(cset)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    threshold = 0.25\n",
    "    F_gurson = F_gurson.flatten()\n",
    "    F = F.flatten()\n",
    "    rel_perc_diff = np.zeros(len(F_gurson))\n",
    "    for i in range(0,len(F_gurson)):\n",
    "        if F_gurson[i] <= threshold:\n",
    "            rel_perc_diff[i] = rel_perc_diff[i-1]\n",
    "        else:\n",
    "            rel_perc_diff[i] = np.absolute((F_gurson[i]-F[i])/F_gurson[i]*100)\n",
    "#     print(np.mean(rel_perc_diff))\n",
    "\n",
    "interact(plot_data_and_potential_field_onlyyields, filename=filename_list, hof_index=hof_index_list,\n",
    "         x_ind=range(5), y_ind=range(5), z_ind=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_numerical_equivalency(filename, hof_index=0, sh=1, svm=1, vvf=1):\n",
    "    data, data_labels, equation = _get_data_and_labels(filename, hof_index)\n",
    "    \n",
    "    equation_2 = equation.copy()\n",
    "    equation_2._use_simplification = True\n",
    "    equation_2._update()\n",
    "    print('Bingo:',equation_2)\n",
    "    eval_data = np.array([sh, svm, vvf])\n",
    "    eval_data = eval_data.reshape(1,3)\n",
    "    syield = 1\n",
    "    gurson = (eval_data[:,1]/syield)**2+2*eval_data[:,2]*np.cosh(1.5*(eval_data[:,0]/syield))-(1+eval_data[:,2]**2)\n",
    "    print('Gurson: (X_1)**2+2*X_2*cosh(1.5*(X_0))-(1+X_2**2)')\n",
    "    equ_eval = equation.evaluate_equation_at(eval_data) # -0.8993549168808034\n",
    "    print('Gurson Result:',gurson)\n",
    "    print('Bingo Result:',equ_eval)\n",
    "    \n",
    "interact(check_numerical_equivalency, filename=filename_list, hof_index=hof_index_list,\n",
    "         sh=(0.5,1.6), svm=(0.1,0.9), vvf=(0,0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_and_value(filename, hof_index, value=\"potential\", x_ind=0, y_ind=1, z_ind=2):\n",
    "    data, data_labels, equation, fit_func = _get_data_and_labels(filename, hof_index, fit_func=True)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    c = \"k\"\n",
    "    if value == \"potential\":\n",
    "        c = equation.evaluate_equation_at(data.x)\n",
    "    if value == \"residual\":\n",
    "        fit_func.training_data = data\n",
    "        c = np.abs(fit_func._fitness_function.evaluate_fitness_vector(equation))\n",
    "    \n",
    "    sc = ax.scatter(data.x[:, x_ind], data.x[:, y_ind], data.x[:, z_ind], c=c)\n",
    "    ax.set_xlabel(data_labels[x_ind])\n",
    "    ax.set_ylabel(data_labels[y_ind])\n",
    "    ax.set_zlabel(data_labels[z_ind])\n",
    "    fig.colorbar(sc)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(plot_data_and_value, filename=filename_list, hof_index=hof_index_list,\n",
    "         value=[\"potential\", \"residual\"], x_ind=range(5), y_ind=range(5), z_ind=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_normailization(filename):\n",
    "    archipelago = load_parallel_archipelago_from_file(filename)\n",
    "    data_x = archipelago.island._full_training_data.x\n",
    "    data_dx = archipelago.island._full_training_data.dx_dt\n",
    "    d1 = h5py.File('d29.hdf5','a') \n",
    "    d1.create_dataset('data', data = data_x)\n",
    "    d1.create_dataset('data_dxdt', data = data_dx)\n",
    "\n",
    "    print(stats.describe(data_dx))\n",
    "    print(np.max(data_dx, axis=0) - np.min(data_dx, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=22, minmax=(array([-0.2199275 , -0.21963304]), array([0.21914258, 0.1737653 ])), mean=array([-0.01014787, -0.05918256]), variance=array([0.03018527, 0.01675408]), skewness=array([0.13516847, 0.3100299 ]), kurtosis=array([-1.6633827 , -1.26154605]))\n",
      "[0.43907008 0.39339834]\n"
     ]
    }
   ],
   "source": [
    "check_normailization(filename_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fs1d29e10_even/pkl_files/ML_project_k35_6_97000.pkl'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
